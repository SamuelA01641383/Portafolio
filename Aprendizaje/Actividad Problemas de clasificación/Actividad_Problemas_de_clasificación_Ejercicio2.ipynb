{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2"
      ],
      "metadata": {
        "id": "vcis5AR4j1eT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determina si es necesario balancear los datos. En caso de que sea afirmativo, en todo este ejercicio tendrás que utilizar alguna estrategia para mitigar el problema de tener una muestra desbalanceada."
      ],
      "metadata": {
        "id": "YW5IMoM5j69s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IXO7a9zjyoh",
        "outputId": "a4fac967-503f-4bc0-cbb6-9d22dc1cc0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases: [1. 1. 1. 1. 1.]\n",
            "Variables (primeras 5 filas):\n",
            " [[ 1.          0.15991005  0.82903782 ...  0.87855426  1.63603899\n",
            "   1.60896884]\n",
            " [ 1.         -1.03964581  0.06158144 ...  0.67610431  0.75054922\n",
            "   1.04006595]\n",
            " [ 1.         -1.41164407 -1.09091459 ...  0.36203866  1.59177889\n",
            "   1.53300746]\n",
            " [ 1.         -2.6459736   0.12978829 ...  2.5321943   0.34460084\n",
            "  -0.867472  ]\n",
            " [ 1.         -1.69286003 -1.59763231 ...  1.38472232  0.45231775\n",
            "   0.7562994 ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Cargar los datos, ignorando la segunda columna\n",
        "data = np.loadtxt('sample_data/M_5.txt')\n",
        "\n",
        "# Separar la primera columna (clases) y las variables (excluyendo la segunda columna)\n",
        "clases = data[:, 0]  # Primera columna (clases)\n",
        "variables = np.delete(data, 1, axis=1)  # Eliminar la segunda columna (ignorada)\n",
        "\n",
        "# Mostrar las primeras filas de las clases y las variables\n",
        "print(\"Clases:\", clases[:5])\n",
        "print(\"Variables (primeras 5 filas):\\n\", variables[:5, :])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Contar la cantidad de ejemplos en cada clase\n",
        "conteo_clases = Counter(clases)\n",
        "\n",
        "# Mostrar el conteo de cada clase\n",
        "print(\"Distribución de clases:\", conteo_clases)\n",
        "\n",
        "# Graficar la distribución de las clases\n",
        "plt.bar(conteo_clases.keys(), conteo_clases.values())\n",
        "plt.xlabel('Clase')\n",
        "plt.ylabel('Cantidad de muestras')\n",
        "plt.title('Distribución de las clases')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "YLIY5Pnsp1n4",
        "outputId": "6e3ab59e-05b1-43cf-c38d-60794410fbaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de clases: Counter({1.0: 90, 2.0: 90, 3.0: 90, 4.0: 90, 5.0: 90, 6.0: 90, 7.0: 89})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5QklEQVR4nO3deVxU9eL/8fewI7JpgmCI+4pbWuaWpaSZa7m0UCFm9bthpnzvLcxcSylvIVqmaV3UykxLTb2Jmlu576mVS+ZWJpoLKCYanN8fPJzbBCjHBoZjr+fjMY8H8zlnzrznNLfe95zPOWMzDMMQAACABbm5OgAAAMCNosgAAADLosgAAADLosgAAADLosgAAADLosgAAADLosgAAADLosgAAADLosgAKBHZ2dkaO3asli5d6uooAG4iFBnAyUaOHCmbzVYi73X33Xfr7rvvtj9fvXq1bDabPv300xJ5/z+y2WwaOXJkocsTEhL00UcfqXnz5iWSp2/fvqpSpYrTtleS/1zNcPbnBKyGIgNcw/Tp02Wz2ewPHx8fhYeHq2PHjpo4caLOnz/vlPc5fvy4Ro4cqZ07dzple6XNnDlztGDBAi1ZskRBQUGujgPgJuLh6gCAFYwePVpVq1bVlStXdOLECa1evVqDBg1ScnKyFi5cqIYNG9rXffnll5WYmGhq+8ePH9eoUaNUpUoVNW7cuMivW7Zsman3KU6//fabPDzy/yvFMAz99NNPWrJkiSpXruyCZABuZhQZoAg6deqkZs2a2Z8PGTJEK1euVJcuXdStWzd9//338vX1lSR5eHgU+B90Z7p48aLKlCkjLy+vYn0fM3x8fAoct9lsSkhIKOE0AP4uOLUE3KB27dpp2LBhOnLkiD788EP7eEFzKZYvX67WrVsrKChIZcuWVe3atfXSSy9JypvXcvvtt0uS4uLi7Kexpk+fLilvHkxUVJS2bdumu+66S2XKlLG/9s9zZK7KycnRSy+9pIoVK8rPz0/dunXTsWPHHNapUqWK+vbtm++1BW3z0qVLGjlypGrVqiUfHx+FhYXpwQcf1MGDB+3rFDRHZseOHerUqZMCAgJUtmxZtW/fXhs3bnRY5+rpu3Xr1ikhIUEVKlSQn5+fHnjgAZ06dSpfvoIsWLBAUVFR8vHxUVRUlObPn1/germ5uUpJSVH9+vXl4+Oj0NBQPfPMMzp79myR3ufPUlNT1a5dO4WEhMjb21v16tXT5MmT8623detWdezYUbfccot8fX1VtWpV9evXr0jvsWTJErVt21b+/v4KCAjQ7bffrlmzZl3zNW+88YZatmyp8uXLy9fXV02bNi1w3tS1vpdXZWdna8SIEapRo4a8vb0VERGhF154QdnZ2aa3BRQHjsgAf8Hjjz+ul156ScuWLdNTTz1V4DrffvutunTpooYNG2r06NHy9vbWDz/8oHXr1kmS6tatq9GjR2v48OF6+umn1aZNG0lSy5Yt7ds4ffq0OnXqpIcffliPPfaYQkNDr5lrzJgxstlsevHFF3Xy5EmlpKQoOjpaO3futB85KqqcnBx16dJFK1as0MMPP6znn39e58+f1/Lly7Vnzx5Vr1690M/dpk0bBQQE6IUXXpCnp6feffdd3X333VqzZk2+Sb/PPfecgoODNWLECB0+fFgpKSkaMGCAPvnkk2vmW7ZsmXr27Kl69eopKSlJp0+fVlxcnG699dZ86z7zzDOaPn264uLiNHDgQB06dEhvv/22duzYoXXr1snT09PUvpk8ebLq16+vbt26ycPDQ4sWLdKzzz6r3NxcxcfHS5JOnjypDh06qEKFCkpMTFRQUJAOHz6sefPmXXf706dPV79+/VS/fn0NGTJEQUFB2rFjh9LS0vToo48W+roJEyaoW7duiomJ0eXLlzV79mz17t1bixcvVufOnSVd/3sp5RW/bt26ae3atXr66adVt25d7d69W+PHj9f+/fu1YMGCIm8LKDYGgEKlpqYakowtW7YUuk5gYKDRpEkT+/MRI0YYf/yf1vjx4w1JxqlTpwrdxpYtWwxJRmpqar5lbdu2NSQZU6ZMKXBZ27Zt7c9XrVplSDIqVapkZGZm2sfnzJljSDImTJhgH4uMjDRiY2Ovu83//Oc/hiQjOTk537q5ubn2vyUZI0aMsD/v0aOH4eXlZRw8eNA+dvz4ccPf39+466677GNX93F0dLTD9gYPHmy4u7sb586dy/e+f9S4cWMjLCzMYb1ly5YZkozIyEj72Ndff21IMj766COH16elpRU4/md//udqGIZx8eLFfOt17NjRqFatmv35/Pnzr/sdKsi5c+cMf39/o3nz5sZvv/3msOyP+yk2NtbhcxaU6/Lly0ZUVJTRrl07+1hRvpcffPCB4ebmZnz99dcO41OmTDEkGevWrSvytoDiwqkl4C8qW7bsNa9eunqVzueff67c3Nwbeg9vb2/FxcUVef0nnnhC/v7+9ue9evVSWFiYvvjiC9Pv/dlnn+mWW27Rc889l29ZYZcj5+TkaNmyZerRo4eqVatmHw8LC9Ojjz6qtWvXKjMz0+E1Tz/9tMP22rRpo5ycHB05cqTQbL/88ot27typ2NhYBQYG2sfvvfde1atXz2HduXPnKjAwUPfee69+/fVX+6Np06YqW7asVq1ade0dUYA/Ht3KyMjQr7/+qrZt2+rHH39URkaGpP/981+8eLGuXLlS5G0vX75c58+fV2JiYr75R9e7DPyPuc6ePauMjAy1adNG27dvt48X5Xs5d+5c1a1bV3Xq1HHYZ+3atZMk+z5zxnccuFEUGeAvunDhgkNp+LOHHnpIrVq1Uv/+/RUaGqqHH35Yc+bMMfUv/EqVKpma2FuzZk2H5zabTTVq1NDhw4eLvI2rDh48qNq1a5uawHzq1CldvHhRtWvXzresbt26ys3NzTdn589XNAUHB0vSNeevXC05f/68kvK994EDB5SRkaGQkBBVqFDB4XHhwgWdPHmyaB/uD9atW6fo6Gj5+fkpKChIFSpUsM8LuVpk2rZtq549e2rUqFG65ZZb1L17d6WmpuabY/JnV+cfRUVFmc61ePFi3XnnnfLx8VG5cuVUoUIFTZ482Z5JKtr38sCBA/r222/z7a9atWpJkn2fOeM7Dtwo5sgAf8FPP/2kjIwM1ahRo9B1fH199dVXX2nVqlX673//q7S0NH3yySdq166dli1bJnd39+u+j9l5LUVxraMpRcnkbIW9p2EYTtl+bm6uQkJC9NFHHxW4vEKFCqa2d/DgQbVv31516tRRcnKyIiIi5OXlpS+++ELjx4+3/0f86g0KN27cqEWLFmnp0qXq16+f3nzzTW3cuFFly5b9y5/tj77++mt169ZNd911l9555x2FhYXJ09NTqampDpOEi/K9zM3NVYMGDZScnFzge0VERBR5W0BxocgAf8EHH3wgSerYseM113Nzc1P79u3Vvn17JScna+zYsRo6dKhWrVql6Ohop98x9sCBAw7PDcPQDz/84HC/m+DgYJ07dy7fa48cOeJwOqh69eratGmTrly5UuTJsBUqVFCZMmW0b9++fMv27t0rNzc3+38E/4rIyEhJ+T+vpHzvXb16dX355Zdq1aqVU4rhokWLlJ2drYULFzocTSrsFNWdd96pO++8U2PGjNGsWbMUExOj2bNnq3///gWuf3US9Z49e65ZlP/ss88+k4+Pj5YuXSpvb2/7eGpqar51r/e9rF69ur755hu1b9/+ut/R620LKC6cWgJu0MqVK/XKK6+oatWqiomJKXS9M2fO5Bu7etO7q6cX/Pz8JKnAYnEjZs6c6TBv59NPP9Uvv/yiTp062ceqV6+ujRs36vLly/axxYsX5zvl07NnT/366696++23871PYUdL3N3d1aFDB33++ecOp7PS09M1a9YstW7dWgEBATf68ezCwsLUuHFjzZgxw+G0yfLly/Xdd985rNunTx/l5OTolVdeybed33//3fS+v3qU4Y/7ICMjI19hOHv2bL799Od//gXp0KGD/P39lZSUpEuXLjksu9ZRKnd3d9lsNuXk5NjHDh8+bL/C6KqifC/79Omjn3/+WdOmTcu37m+//aasrKwibwsoLhyRAYpgyZIl2rt3r37//Xelp6dr5cqVWr58uSIjI7Vw4cJCbwYn5d0V+KuvvlLnzp0VGRmpkydP6p133tGtt96q1q1bS8orFUFBQZoyZYr8/f3l5+en5s2bq2rVqjeUt1y5cmrdurXi4uKUnp6ulJQU1ahRw+ES8f79++vTTz/Vfffdpz59+ujgwYP68MMP811O/cQTT2jmzJlKSEjQ5s2b1aZNG2VlZenLL7/Us88+q+7duxeY4dVXX7XfW+TZZ5+Vh4eH3n33XWVnZ2vcuHE39LkKkpSUpM6dO6t169bq16+fzpw5o7feekv169fXhQsX7Ou1bdtWzzzzjJKSkrRz50516NBBnp6eOnDggObOnasJEyaoV69eRX7fDh06yMvLS127dtUzzzyjCxcuaNq0aQoJCdEvv/xiX2/GjBl655139MADD6h69eo6f/68pk2bpoCAAN1///2Fbj8gIEDjx49X//79dfvtt+vRRx9VcHCwvvnmG128eFEzZswo8HWdO3dWcnKy7rvvPj366KM6efKkJk2apBo1amjXrl329YryvXz88cc1Z84c/b//9/+0atUqtWrVSjk5Odq7d6/mzJmjpUuXqlmzZkXaFlBsXHnJFFDaXb00+OrDy8vLqFixonHvvfcaEyZMcLjE+ao/X6a7YsUKo3v37kZ4eLjh5eVlhIeHG4888oixf/9+h9d9/vnnRr169QwPDw+HS7Hbtm1r1K9fv8B8hV1+/fHHHxtDhgwxQkJCDF9fX6Nz587GkSNH8r3+zTffNCpVqmR4e3sbrVq1MrZu3Zpvm4aRdznv0KFDjapVqxqenp5GxYoVjV69ejlcWq0/XX5tGIaxfft2o2PHjkbZsmWNMmXKGPfcc4+xfv36Avfxny9PvvpZVq1aVeBn/6PPPvvMqFu3ruHt7W3Uq1fPmDdvXoGXJRuGYUydOtVo2rSp4evra/j7+xsNGjQwXnjhBeP48ePXfI+CLr9euHCh0bBhQ8PHx8eoUqWK8frrr9svVz906JB9HzzyyCNG5cqVDW9vbyMkJMTo0qWLsXXr1ut+rqvv0bJlS8PX19cICAgw7rjjDuPjjz+2Ly/oc77//vtGzZo1DW9vb6NOnTpGamrqDX8vL1++bLz++utG/fr1DW9vbyM4ONho2rSpMWrUKCMjI8PUtoDiYDMMJ82kAwAAKGHMkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZ1098QLzc3V8ePH5e/v7/TbwMPAACKh2EYOn/+vMLDw+XmVvhxl5u+yBw/ftwpv+kCAABK3rFjx3TrrbcWuvymLzL+/v6S8naEM37bBQAAFL/MzExFRETY/ztemJu+yFw9nRQQEECRAQDAYq77y+sllAMAAMDpKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyPFwdwMqqJP7X1RGc7vBrnW/odeyLPOyHPOyH/2Ff5GE/oLhwRAYAAFgWRQYAAFgWRQYAAFgWc2QAACghzBVyPo7IAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy6LIAAAAy3JpkcnJydGwYcNUtWpV+fr6qnr16nrllVdkGIZ9HcMwNHz4cIWFhcnX11fR0dE6cOCAC1MDAIDSwqVF5vXXX9fkyZP19ttv6/vvv9frr7+ucePG6a233rKvM27cOE2cOFFTpkzRpk2b5Ofnp44dO+rSpUsuTA4AAEoDD1e++fr169W9e3d17txZklSlShV9/PHH2rx5s6S8ozEpKSl6+eWX1b17d0nSzJkzFRoaqgULFujhhx92WXYAAOB6Lj0i07JlS61YsUL79++XJH3zzTdau3atOnXqJEk6dOiQTpw4oejoaPtrAgMD1bx5c23YsKHAbWZnZyszM9PhAQAAbk4uPSKTmJiozMxM1alTR+7u7srJydGYMWMUExMjSTpx4oQkKTQ01OF1oaGh9mV/lpSUpFGjRhVvcAAAUCq49IjMnDlz9NFHH2nWrFnavn27ZsyYoTfeeEMzZsy44W0OGTJEGRkZ9sexY8ecmBgAAJQmLj0i869//UuJiYn2uS4NGjTQkSNHlJSUpNjYWFWsWFGSlJ6errCwMPvr0tPT1bhx4wK36e3tLW9v72LPDgAAXM+lR2QuXrwoNzfHCO7u7srNzZUkVa1aVRUrVtSKFSvsyzMzM7Vp0ya1aNGiRLMCAIDSx6VHZLp27aoxY8aocuXKql+/vnbs2KHk5GT169dPkmSz2TRo0CC9+uqrqlmzpqpWraphw4YpPDxcPXr0cGV0AABQCri0yLz11lsaNmyYnn32WZ08eVLh4eF65plnNHz4cPs6L7zwgrKysvT000/r3Llzat26tdLS0uTj4+PC5AAAoDRwaZHx9/dXSkqKUlJSCl3HZrNp9OjRGj16dMkFAwAAlsBvLQEAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMv6y0UmJydHO3fu1NmzZ52RBwAAoMhMF5lBgwbp/fffl5RXYtq2bavbbrtNERERWr16tbPzAQAAFMp0kfn000/VqFEjSdKiRYt06NAh7d27V4MHD9bQoUOdHhAAAKAwpovMr7/+qooVK0qSvvjiC/Xu3Vu1atVSv379tHv3bqcHBAAAKIzpIhMaGqrvvvtOOTk5SktL07333itJunjxotzd3Z0eEAAAoDAeZl8QFxenPn36KCwsTDabTdHR0ZKkTZs2qU6dOk4PCAAAUBjTRWbkyJGKiorSsWPH1Lt3b3l7e0uS3N3dlZiY6PSAAAAAhTFdZCSpV69e+cZiY2P/chgAAAAzbqjIZGVlac2aNTp69KguX77ssGzgwIFOCQYAAHA9povMjh07dP/99+vixYvKyspSuXLl9Ouvv6pMmTIKCQmhyAAAgBJj+qqlwYMHq2vXrjp79qx8fX21ceNGHTlyRE2bNtUbb7xRHBkBAAAKZLrI7Ny5U//3f/8nNzc3ubu7Kzs7WxERERo3bpxeeuml4sgIAABQINNFxtPTU25ueS8LCQnR0aNHJUmBgYE6duyYc9MBAABcg+k5Mk2aNNGWLVtUs2ZNtW3bVsOHD9evv/6qDz74QFFRUcWREQAAoECmj8iMHTtWYWFhkqQxY8YoODhY//jHP3Tq1ClNnTrV6QEBAAAKY+qIjGEYCgkJsR95CQkJUVpaWrEEAwAAuB5TR2QMw1CNGjWYCwMAAEoFU0XGzc1NNWvW1OnTp4srDwAAQJGZniPz2muv6V//+pf27NlTHHkAAACKzPRVS0888YQuXryoRo0aycvLS76+vg7Lz5w547RwAAAA12K6yIwfP142m604sgAAAJhiusj07du3GGIAAACYZ3qOjLu7u06ePJlv/PTp03J3dzcd4Oeff9Zjjz2m8uXLy9fXVw0aNNDWrVvtyw3D0PDhwxUWFiZfX19FR0frwIEDpt8HAADcfEwXGcMwChzPzs6Wl5eXqW2dPXtWrVq1kqenp5YsWaLvvvtOb775poKDg+3rjBs3ThMnTtSUKVO0adMm+fn5qWPHjrp06ZLZ6AAA4CZT5FNLEydOlCTZbDa99957Klu2rH1ZTk6OvvrqK9WpU8fUm7/++uuKiIhQamqqfaxq1ar2vw3DUEpKil5++WV1795dkjRz5kyFhoZqwYIFevjhh029HwAAuLkUuciMHz9eUl65mDJlisNpJC8vL1WpUkVTpkwx9eYLFy5Ux44d1bt3b61Zs0aVKlXSs88+q6eeekqSdOjQIZ04cULR0dH21wQGBqp58+basGFDgUUmOztb2dnZ9ueZmZmmMgEAAOsocpE5dOiQJOmee+7RvHnzHE7/3Kgff/xRkydPVkJCgl566SVt2bJFAwcOlJeXl2JjY3XixAlJUmhoqMPrQkND7cv+LCkpSaNGjfrL2QAAQOlneo7MqlWrHEpMTk6Odu7cqbNnz5p+89zcXN12220aO3asmjRpoqefflpPPfWU6SM7fzRkyBBlZGTYH/ycAgAANy/TRWbQoEF6//33JeWVmLvuuku33XabIiIitHr1alPbCgsLU7169RzG6tatq6NHj0qSKlasKElKT093WCc9Pd2+7M+8vb0VEBDg8AAAADcn00Vm7ty5atSokSRp0aJFOnz4sPbu3avBgwdr6NChprbVqlUr7du3z2Fs//79ioyMlJQ38bdixYpasWKFfXlmZqY2bdqkFi1amI0OAABuMqaLzOnTp+1HQ7744gv17t1btWrVUr9+/bR7925T2xo8eLA2btyosWPH6ocfftCsWbM0depUxcfHS8q7QmrQoEF69dVXtXDhQu3evVtPPPGEwsPD1aNHD7PRAQDATcb0nX1DQ0P13XffKSwsTGlpaZo8ebIk6eLFi6ZviHf77bdr/vz5GjJkiEaPHq2qVasqJSVFMTEx9nVeeOEFZWVl6emnn9a5c+fUunVrpaWlycfHx2x0AABwkzFdZOLi4tSnTx+FhYXJZrPZL43etGmT6fvISFKXLl3UpUuXQpfbbDaNHj1ao0ePNr1tAABwczNdZEaOHKmoqCgdO3ZMvXv3lre3t6S8ny5ITEx0ekAAAIDCmC4yktSrVy9JcviZgNjYWOckAgAAKCLTk31zcnL0yiuvqFKlSipbtqx+/PFHSdKwYcPsl2UDAACUBNNFZsyYMZo+fbrGjRvn8CORUVFReu+995waDgAA4FpMF5mZM2dq6tSpiomJcbhKqVGjRtq7d69TwwEAAFyL6SLz888/q0aNGvnGc3NzdeXKFaeEAgAAKArTRaZevXr6+uuv841/+umnatKkiVNCAQAAFIXpq5aGDx+u2NhY/fzzz8rNzdW8efO0b98+zZw5U4sXLy6OjAAAAAUyfUSme/fuWrRokb788kv5+flp+PDh+v7777Vo0SLde++9xZERAACgQDd0H5k2bdpo+fLlzs4CAABgiukjMgAAAKWF6SMybm5ustlshS7Pycn5S4EAAACKynSRmT9/vsPzK1euaMeOHZoxY4ZGjRrltGAAAADXY7rIdO/ePd9Yr169VL9+fX3yySd68sknnRIMAADgepw2R+bOO+/UihUrnLU5AACA63JKkfntt980ceJEVapUyRmbAwAAKBLTp5aCg4MdJvsahqHz58+rTJky+vDDD50aDgAA4FpMF5mUlBSH525ubqpQoYKaN2+u4OBgZ+UCAAC4LtNFJjY2tjhyAAAAmHZDd/a9dOmSdu3apZMnTyo3N9dhWbdu3ZwSDAAA4HpMF5m0tDQ9/vjjOn36dL5lNpuNG+IBAIASY/qqpeeee059+vTRL7/8otzcXIcHJQYAAJQk00UmPT1dCQkJCg0NLY48AAAARWa6yPTq1UurV68uhigAAADmmJ4j8/bbb6t37976+uuv1aBBA3l6ejosHzhwoNPCAQAAXIvpIvPxxx9r2bJl8vHx0erVqx1ujmez2SgyAACgxJguMkOHDtWoUaOUmJgoNzen/VQTAACAaaabyOXLl/XQQw9RYgAAgMuZbiOxsbH65JNPiiMLAACAKaZPLeXk5GjcuHFaunSpGjZsmG+yb3JystPCAQAAXIvpIrN79241adJEkrRnzx6HZX+c+AsAAFDcTBeZVatWFUcOAAAA05ixCwAALIsiAwAALIsiAwAALIsiAwAALIsiAwAALOuGiswHH3ygVq1aKTw8XEeOHJEkpaSk6PPPP3dqOAAAgGsxXWQmT56shIQE3X///Tp37pxycnIkSUFBQUpJSXF2PgAAgEKZLjJvvfWWpk2bpqFDh8rd3d0+3qxZM+3evdup4QAAAK7FdJE5dOiQ/c6+f+Tt7a2srCynhAIAACgK00WmatWq2rlzZ77xtLQ01a1b1xmZAAAAisT0TxQkJCQoPj5ely5dkmEY2rx5sz7++GMlJSXpvffeK46MAAAABTJdZPr37y9fX1+9/PLLunjxoh599FGFh4drwoQJevjhh4sjIwAAQIFMFxlJiomJUUxMjC5evKgLFy4oJCTE2bkAAACu64aKzFVlypRRmTJlnJUFAADAlCIVmSZNmshmsxVpg9u3b/9LgQAAAIqqSEWmR48e9r8vXbqkd955R/Xq1VOLFi0kSRs3btS3336rZ599tlhCAgAAFKRIRWbEiBH2v/v376+BAwfqlVdeybfOsWPHnJsOAADgGkzfR2bu3Ll64okn8o0/9thj+uyzz5wSCgAAoChMFxlfX1+tW7cu3/i6devk4+PjlFAAAABFYfqqpUGDBukf//iHtm/frjvuuEOStGnTJv3nP//RsGHDnB4QAACgMKaLTGJioqpVq6YJEyboww8/lCTVrVtXqamp6tOnj9MDAgAAFOaG7iPTp08fSgsAAHA503NkAAAASguKDAAAsCyKDAAAsCyKDAAAsCyKDAAAsKwiXbWUkJBQ5A0mJyffcBgAAAAzilRkduzY4fB8+/bt+v3331W7dm1J0v79++Xu7q6mTZs6PyEAAEAhilRkVq1aZf87OTlZ/v7+mjFjhoKDgyVJZ8+eVVxcnNq0aVM8KQEAAApgeo7Mm2++qaSkJHuJkaTg4GC9+uqrevPNN50aDgAA4FpMF5nMzEydOnUq3/ipU6d0/vx5p4QCAAAoCtNF5oEHHlBcXJzmzZunn376ST/99JM+++wzPfnkk3rwwQeLIyMAAECBTP/W0pQpU/TPf/5Tjz76qK5cuZK3EQ8PPfnkk/r3v//t9IAAAACFMV1kypQpo3feeUf//ve/dfDgQUlS9erV5efn5/RwAAAA13LDN8Tz8/NTw4YN1bBhQ6eUmNdee002m02DBg2yj126dEnx8fEqX768ypYtq549eyo9Pf0vvxcAALg5mD4iI0lbt27VnDlzdPToUV2+fNlh2bx580xvb8uWLXr33XfVsGFDh/HBgwfrv//9r+bOnavAwEANGDBADz74oNatW3cjsQEAwE3G9BGZ2bNnq2XLlvr+++81f/58XblyRd9++61WrlypwMBA0wEuXLigmJgYTZs2zeGS7oyMDL3//vtKTk5Wu3bt1LRpU6Wmpmr9+vXauHGj6fcBAAA3H9NFZuzYsRo/frwWLVokLy8vTZgwQXv37lWfPn1UuXJl0wHi4+PVuXNnRUdHO4xv27ZNV65ccRivU6eOKleurA0bNhS6vezsbGVmZjo8AADAzcl0kTl48KA6d+4sSfLy8lJWVpZsNpsGDx6sqVOnmtrW7NmztX37diUlJeVbduLECXl5eSkoKMhhPDQ0VCdOnCh0m0lJSQoMDLQ/IiIiTGUCAADWYbrIBAcH2298V6lSJe3Zs0eSdO7cOV28eLHI2zl27Jief/55ffTRR/Lx8TEbo1BDhgxRRkaG/XHs2DGnbRsAAJQupif73nXXXVq+fLkaNGig3r176/nnn9fKlSu1fPlytW/fvsjb2bZtm06ePKnbbrvNPpaTk6OvvvpKb7/9tpYuXarLly/r3LlzDkdl0tPTVbFixUK36+3tLW9vb7MfCwAAWJDpIvP222/r0qVLkqShQ4fK09NT69evV8+ePfXyyy8XeTvt27fX7t27Hcbi4uJUp04dvfjii4qIiJCnp6dWrFihnj17SpL27duno0ePqkWLFmZjAwCAm5DpIlOuXDn7325ubkpMTLyhN/b391dUVJTDmJ+fn8qXL28ff/LJJ5WQkKBy5copICBAzz33nFq0aKE777zzht4TAADcXIpUZMxc+RMQEHDDYf5s/PjxcnNzU8+ePZWdna2OHTvqnXfecdr2AQCAtRWpyAQFBclmsxVpgzk5OTccZvXq1Q7PfXx8NGnSJE2aNOmGtwkAAG5eRSoyq1atsv99+PBhJSYmqm/fvva5Khs2bNCMGTMKvIwaAACguBSpyLRt29b+9+jRo5WcnKxHHnnEPtatWzc1aNBAU6dOVWxsrPNTAgAAFMD0fWQ2bNigZs2a5Rtv1qyZNm/e7JRQAAAARWG6yERERGjatGn5xt977z3uogsAAEqU6cuvx48fr549e2rJkiVq3ry5JGnz5s06cOCAPvvsM6cHBAAAKIzpIzL333+/9u/fr65du+rMmTM6c+aMunbtqv379+v+++8vjowAAAAFMn1ERso7vTR27FhnZwEAADClSEVm165dioqKkpubm3bt2nXNdRs2bOiUYAAAANdTpCLTuHFjnThxQiEhIWrcuLFsNpsMw8i3ns1m+0s3xAMAADCjSEXm0KFDqlChgv1vAACA0qBIRSYyMtL+95EjR9SyZUt5eDi+9Pfff9f69esd1gUAAChOpq9auueee3TmzJl84xkZGbrnnnucEgoAAKAoTBcZwzAK/AHJ06dPy8/PzymhAAAAiqLIl18/+OCDkvIm9Pbt21fe3t72ZTk5Odq1a5datmzp/IQAAACFKHKRCQwMlJR3RMbf31++vr72ZV5eXrrzzjv11FNPOT8hAABAIYpcZFJTUyVJVapU0T//+U9OIwEAAJczfWffESNGFEcOAAAA00xP9k1PT9fjjz+u8PBweXh4yN3d3eEBAABQUkwfkenbt6+OHj2qYcOGKSwsrMArmAAAAEqC6SKzdu1aff3112rcuHExxAEAACg606eWIiIiCvydJQAAgJJmusikpKQoMTFRhw8fLoY4AAAARWf61NJDDz2kixcvqnr16ipTpow8PT0dlhf08wUAAADFwXSRSUlJKYYYAAAA5pkuMrGxscWRAwAAwDTTReaPLl26pMuXLzuMBQQE/KVAAAAARWV6sm9WVpYGDBigkJAQ+fn5KTg42OEBAABQUkwXmRdeeEErV67U5MmT5e3trffee0+jRo1SeHi4Zs6cWRwZAQAACmT61NKiRYs0c+ZM3X333YqLi1ObNm1Uo0YNRUZG6qOPPlJMTExx5AQAAMjH9BGZM2fOqFq1apLy5sNcvdy6devW+uqrr5ybDgAA4BpMF5lq1arp0KFDkqQ6depozpw5kvKO1AQFBTk1HAAAwLWYLjJxcXH65ptvJEmJiYmaNGmSfHx8NHjwYP3rX/9yekAAAIDCmJ4jM3jwYPvf0dHR2rt3r7Zt26YaNWqoYcOGTg0HAABwLX/pPjKSFBkZqcjISGdkAQAAMKXIp5ZWrlypevXqKTMzM9+yjIwM1a9fX19//bVTwwEAAFxLkYtMSkqKnnrqqQLv3BsYGKhnnnlGycnJTg0HAABwLUUuMt98843uu+++Qpd36NBB27Ztc0ooAACAoihykUlPT5enp2ehyz08PHTq1CmnhAIAACiKIheZSpUqac+ePYUu37Vrl8LCwpwSCgAAoCiKXGTuv/9+DRs2TJcuXcq37LffftOIESPUpUsXp4YDAAC4liJffv3yyy9r3rx5qlWrlgYMGKDatWtLkvbu3atJkyYpJydHQ4cOLbagAAAAf1bkIhMaGqr169frH//4h4YMGSLDMCRJNptNHTt21KRJkxQaGlpsQQEAAP7M1A3xIiMj9cUXX+js2bP64YcfZBiGatasqeDg4OLKBwAAUKgburNvcHCwbr/9dmdnAQAAMMX0j0YCAACUFhQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWRQZAABgWS4tMklJSbr99tvl7++vkJAQ9ejRQ/v27XNY59KlS4qPj1f58uVVtmxZ9ezZU+np6S5KDAAAShOXFpk1a9YoPj5eGzdu1PLly3XlyhV16NBBWVlZ9nUGDx6sRYsWae7cuVqzZo2OHz+uBx980IWpAQBAaeHhyjdPS0tzeD59+nSFhIRo27Ztuuuuu5SRkaH3339fs2bNUrt27SRJqampqlu3rjZu3Kg777zTFbEBAEApUarmyGRkZEiSypUrJ0natm2brly5oujoaPs6derUUeXKlbVhwwaXZAQAAKWHS4/I/FFubq4GDRqkVq1aKSoqSpJ04sQJeXl5KSgoyGHd0NBQnThxosDtZGdnKzs72/48MzOz2DIDAADXKjVHZOLj47Vnzx7Nnj37L20nKSlJgYGB9kdERISTEgIAgNKmVBSZAQMGaPHixVq1apVuvfVW+3jFihV1+fJlnTt3zmH99PR0VaxYscBtDRkyRBkZGfbHsWPHijM6AABwIZcWGcMwNGDAAM2fP18rV65U1apVHZY3bdpUnp6eWrFihX1s3759Onr0qFq0aFHgNr29vRUQEODwAAAANyeXzpGJj4/XrFmz9Pnnn8vf398+7yUwMFC+vr4KDAzUk08+qYSEBJUrV04BAQF67rnn1KJFC65YAgAAri0ykydPliTdfffdDuOpqanq27evJGn8+PFyc3NTz549lZ2drY4dO+qdd94p4aQAAKA0cmmRMQzjuuv4+Pho0qRJmjRpUgkkAgAAVlIqJvsCAADcCIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLEsUmUmTJqlKlSry8fFR8+bNtXnzZldHAgAApUCpLzKffPKJEhISNGLECG3fvl2NGjVSx44ddfLkSVdHAwAALlbqi0xycrKeeuopxcXFqV69epoyZYrKlCmj//znP66OBgAAXKxUF5nLly9r27Ztio6Oto+5ubkpOjpaGzZscGEyAABQGni4OsC1/Prrr8rJyVFoaKjDeGhoqPbu3Vvga7Kzs5WdnW1/npGRIUnKzMx0er7c7ItO36ar3eh+Yl/kYT/kYT/8D/siD/shD/vB/HYNw7jmeqW6yNyIpKQkjRo1Kt94RESEC9JYT2CKqxOUHuyLPOyHPOyH/2Ff5GE/5Cnu/XD+/HkFBgYWurxUF5lbbrlF7u7uSk9PdxhPT09XxYoVC3zNkCFDlJCQYH+em5urM2fOqHz58rLZbMWat7hkZmYqIiJCx44dU0BAgKvjuAz74X/YF3nYD3nYD//DvshzM+wHwzB0/vx5hYeHX3O9Ul1kvLy81LRpU61YsUI9evSQlFdMVqxYoQEDBhT4Gm9vb3l7ezuMBQUFFXPSkhEQEGDZL6QzsR/+h32Rh/2Qh/3wP+yLPFbfD9c6EnNVqS4ykpSQkKDY2Fg1a9ZMd9xxh1JSUpSVlaW4uDhXRwMAAC5W6ovMQw89pFOnTmn48OE6ceKEGjdurLS0tHwTgAEAwN9PqS8ykjRgwIBCTyX9HXh7e2vEiBH5Tpn93bAf/od9kYf9kIf98D/sizx/p/1gM653XRMAAEApVapviAcAAHAtFBkAAGBZFBkAAGBZFBkAAGBZFJlS7KuvvlLXrl0VHh4um82mBQsWuDqSSyQlJen222+Xv7+/QkJC1KNHD+3bt8/VsUrc5MmT1bBhQ/sNrlq0aKElS5a4OpbLvfbaa7LZbBo0aJCro5S4kSNHymazOTzq1Knj6lgu8fPPP+uxxx5T+fLl5evrqwYNGmjr1q2ujlXiqlSpku87YbPZFB8f7+poxYYiU4plZWWpUaNGmjRpkqujuNSaNWsUHx+vjRs3avny5bpy5Yo6dOigrKwsV0crUbfeeqtee+01bdu2TVu3blW7du3UvXt3ffvtt66O5jJbtmzRu+++q4YNG7o6isvUr19fv/zyi/2xdu1aV0cqcWfPnlWrVq3k6empJUuW6LvvvtObb76p4OBgV0crcVu2bHH4PixfvlyS1Lt3bxcnKz6WuI/M31WnTp3UqVMnV8dwubS0NIfn06dPV0hIiLZt26a77rrLRalKXteuXR2ejxkzRpMnT9bGjRtVv359F6VynQsXLigmJkbTpk3Tq6++6uo4LuPh4VHob8/9Xbz++uuKiIhQamqqfaxq1aouTOQ6FSpUcHj+2muvqXr16mrbtq2LEhU/jsjAcjIyMiRJ5cqVc3ES18nJydHs2bOVlZWlFi1auDqOS8THx6tz586Kjo52dRSXOnDggMLDw1WtWjXFxMTo6NGjro5U4hYuXKhmzZqpd+/eCgkJUZMmTTRt2jRXx3K5y5cv68MPP1S/fv0s+6PJRcERGVhKbm6uBg0apFatWikqKsrVcUrc7t271aJFC126dElly5bV/PnzVa9ePVfHKnGzZ8/W9u3btWXLFldHcanmzZtr+vTpql27tn755ReNGjVKbdq00Z49e+Tv7+/qeCXmxx9/1OTJk5WQkKCXXnpJW7Zs0cCBA+Xl5aXY2FhXx3OZBQsW6Ny5c+rbt6+roxQrigwsJT4+Xnv27PlbzgOQpNq1a2vnzp3KyMjQp59+qtjYWK1Zs+ZvVWaOHTum559/XsuXL5ePj4+r47jUH089N2zYUM2bN1dkZKTmzJmjJ5980oXJSlZubq6aNWumsWPHSpKaNGmiPXv2aMqUKX/rIvP++++rU6dOCg8Pd3WUYsWpJVjGgAEDtHjxYq1atUq33nqrq+O4hJeXl2rUqKGmTZsqKSlJjRo10oQJE1wdq0Rt27ZNJ0+e1G233SYPDw95eHhozZo1mjhxojw8PJSTk+PqiC4TFBSkWrVq6YcffnB1lBIVFhaWr8zXrVv3b3ma7aojR47oyy+/VP/+/V0dpdhxRAalnmEYeu655zR//nytXr36bzuJryC5ubnKzs52dYwS1b59e+3evdthLC4uTnXq1NGLL74od3d3FyVzvQsXLujgwYN6/PHHXR2lRLVq1SrfLRn279+vyMhIFyVyvdTUVIWEhKhz586ujlLsKDKl2IULFxz+n9WhQ4e0c+dOlStXTpUrV3ZhspIVHx+vWbNm6fPPP5e/v79OnDghSQoMDJSvr6+L05WcIUOGqFOnTqpcubLOnz+vWbNmafXq1Vq6dKmro5Uof3//fPOj/Pz8VL58+b/dvKl//vOf6tq1qyIjI3X8+HGNGDFC7u7ueuSRR1wdrUQNHjxYLVu21NixY9WnTx9t3rxZU6dO1dSpU10dzSVyc3OVmpqq2NhYeXj8Df4zb6DUWrVqlSEp3yM2NtbV0UpUQftAkpGamurqaCWqX79+RmRkpOHl5WVUqFDBaN++vbFs2TJXxyoV2rZtazz//POujlHiHnroISMsLMzw8vIyKlWqZDz00EPGDz/84OpYLrFo0SIjKirK8Pb2NurUqWNMnTrV1ZFcZunSpYYkY9++fa6OUiJshmEYrqlQAAAAfw2TfQEAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZACUajabTQsWLHB1DAClFEUGgEudOHFCzz33nKpVqyZvb29FRESoa9euWrFihaujAbCAv8GPMAAorQ4fPqxWrVopKChI//73v9WgQQNduXJFS5cuVXx8vPbu3evqiABKOY7IAHCZZ599VjabTZs3b1bPnj1Vq1Yt1a9fXwkJCdq4cWOBr3nxxRdVq1YtlSlTRtWqVdOwYcN05coV+/JvvvlG99xzj/z9/RUQEKCmTZtq69at9uVr165VmzZt5Ovrq4iICA0cOFBZWVnF/lkBFA+KDACXOHPmjNLS0hQfHy8/P798y4OCggp8nb+/v6ZPn67vvvtOEyZM0LRp0zR+/Hj78piYGN16663asmWLtm3bpsTERHl6ekqSDh48qPvuu089e/bUrl279Mknn2jt2rUaMGBAsXxGAMWPH40E4BKbN29W8+bNNW/ePD3wwAOFrmez2TR//nz16NGjwOVvvPGGZs+ebT/qEhAQoLfeekuxsbH51u3fv7/c3d317rvv2sfWrl2rtm3bKisrSz4+Pn/tQwEoccyRAeASN/r/oT755BNNnDhRBw8e1IULF/T7778rICDAvjwhIUH9+/fXBx98oOjoaPXu3VvVq1eXlHfaadeuXfroo48ccuTm5urQoUOqW7fuX/tQAEocp5YAuETNmjVls9lMTejdsGGDYmJidP/992vx4sXasWOHhg4dqsuXL9vXGTlypL799lt17txZK1euVL169TR//nxJ0oULF/TMM89o586d9sc333yjAwcO2MsOAGvhiAwAlyhXrpw6duyoSZMmaeDAgfnmyZw7dy7fPJn169crMjJSQ4cOtY8dOXIk37Zr1aqlWrVqafDgwXrkkUeUmpqqBx54QLfddpu+++471ahRo1g+E4CSxxEZAC4zadIk5eTk6I477tBnn32mAwcO6Pvvv9fEiRPVokWLfOvXrFlTR48e1ezZs3Xw4EFNnDjRfrRFkn777TcNGDBAq1ev1pEjR7Ru3Tpt2bLFfsroxRdf1Pr16zVgwADt3LlTBw4c0Oeff85kX8DCKDIAXKZatWravn277rnnHv3f//2foqKidO+992rFihWaPHlyvvW7deumwYMHa8CAAWrcuLHWr1+vYcOG2Ze7u7vr9OnTeuKJJ1SrVi316dNHnTp10qhRoyRJDRs21Jo1a7R//361adNGTZo00fDhwxUeHl5inxmAc3HVEgAAsCyOyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMv6/6Ub6AzZVu04AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que ya esta balanceado y no es necesario utilizar alguna estrategia para mitigar el problema de tener una muestra desbalanceada"
      ],
      "metadata": {
        "id": "hz-8r3wLqEsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalúa al menos 8 modelos de clasificación distintos utilizando validación cruzada, y determina cuál de ellos es el más efectivo."
      ],
      "metadata": {
        "id": "eIX9u18iqMOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Escalar las variables\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Definir los modelos\n",
        "modelos = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Gaussian Naive Bayes': GaussianNB(),\n",
        "    'Multilayer Perceptron': MLPClassifier(max_iter=1000),\n",
        "    'AdaBoost': AdaBoostClassifier()\n",
        "}\n",
        "\n",
        "# Evaluar los modelos con validación cruzada\n",
        "resultados = {}\n",
        "for nombre, modelo in modelos.items():\n",
        "    # Crear un pipeline que escale las variables y aplique el modelo\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', scaler),\n",
        "        ('classifier', modelo)\n",
        "    ])\n",
        "\n",
        "    # Validación cruzada con 5 particiones\n",
        "    scores = cross_val_score(pipeline, variables, clases, cv=5, scoring='accuracy')\n",
        "\n",
        "    # Guardar los resultados\n",
        "    resultados[nombre] = np.mean(scores)\n",
        "    print(f\"{nombre}: Accuracy promedio = {np.mean(scores):.4f}\")\n",
        "\n",
        "# Determinar el modelo más efectivo\n",
        "mejor_modelo = max(resultados, key=resultados.get)\n",
        "print(f\"\\nEl modelo más efectivo es: {mejor_modelo} con una precisión de {resultados[mejor_modelo]:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXOSqvjkrazW",
        "outputId": "1ff0c45b-9b7b-442c-92af-ab337622931f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Accuracy promedio = 0.9602\n",
            "Support Vector Machine: Accuracy promedio = 0.9348\n",
            "Decision Tree: Accuracy promedio = 0.9904\n",
            "Random Forest: Accuracy promedio = 0.9252\n",
            "K-Nearest Neighbors: Accuracy promedio = 0.8393\n",
            "Gaussian Naive Bayes: Accuracy promedio = 1.0000\n",
            "Multilayer Perceptron: Accuracy promedio = 0.9125\n",
            "AdaBoost: Accuracy promedio = 0.4565\n",
            "\n",
            "El modelo más efectivo es: Gaussian Naive Bayes con una precisión de 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escoge al menos dos clasificadores que hayas evaluado en el paso anterior e identifica sus hiperparámetros. Lleva a cabo el proceso de validación cruzada anidada para evaluar los dos modelos con la selección óptima de hiperparámetros."
      ],
      "metadata": {
        "id": "064p4lq0vESq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNeighborsClassifier y el DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "LB9hnIX0vG4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# Configuración de la validación cruzada anidada\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Definir los hiperparámetros para cada modelo\n",
        "param_grid_knn = {\n",
        "    'classifier__n_neighbors': np.arange(1, 21)  # Probar valores de k entre 1 y 20\n",
        "}\n",
        "\n",
        "param_grid_tree = {\n",
        "    'classifier__max_depth': np.arange(1, 21)  # Probar valores de max_depth entre 1 y 20\n",
        "}\n",
        "\n",
        "# Modelos a evaluar con validación cruzada anidada\n",
        "modelos = {\n",
        "    'K-Nearest Neighbors': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'param_grid': param_grid_knn\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'param_grid': param_grid_tree\n",
        "    }\n",
        "}\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "# Evaluar cada modelo con validación cruzada anidada\n",
        "for nombre, info in modelos.items():\n",
        "    print(f\"Evaluando {nombre}...\")\n",
        "\n",
        "    # Crear un pipeline que escale las variables y aplique el modelo\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', info['model'])\n",
        "    ])\n",
        "\n",
        "    # Configurar GridSearchCV para validación cruzada anidada\n",
        "    grid_search = GridSearchCV(pipeline, info['param_grid'], cv=outer_cv, scoring='accuracy')\n",
        "\n",
        "    # Validación cruzada anidada\n",
        "    grid_search.fit(variables, clases)\n",
        "\n",
        "    # Guardar los resultados\n",
        "    resultados[nombre] = {\n",
        "        'mejor_modelo': grid_search.best_estimator_,\n",
        "        'mejores_parametros': grid_search.best_params_,\n",
        "        'accuracy_promedio': np.mean(grid_search.cv_results_['mean_test_score'])\n",
        "    }\n",
        "\n",
        "# Imprimir los resultados\n",
        "for nombre, info in resultados.items():\n",
        "    print(f\"\\n{nombre}:\")\n",
        "    print(f\"  Mejor Modelo: {info['mejor_modelo']}\")\n",
        "    print(f\"  Mejores Hiperparámetros: {info['mejores_parametros']}\")\n",
        "    print(f\"  Precisión Promedio: {info['accuracy_promedio']:.4f}\")\n",
        "\n",
        "# Evaluar el modelo final con la mejor configuración en todo el conjunto de datos\n",
        "for nombre, info in resultados.items():\n",
        "    print(f\"\\nEvaluando el modelo final para {nombre}...\")\n",
        "    final_model = info['mejor_modelo']\n",
        "    y_pred = cross_val_predict(final_model, variables, clases, cv=5)\n",
        "    print(classification_report(clases, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu0do7FMvAKM",
        "outputId": "49e4bd0e-4b20-416d-99f6-0fc80b0fe03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando K-Nearest Neighbors...\n",
            "Evaluando Decision Tree...\n",
            "\n",
            "K-Nearest Neighbors:\n",
            "  Mejor Modelo: Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('classifier', KNeighborsClassifier(n_neighbors=12))])\n",
            "  Mejores Hiperparámetros: {'classifier__n_neighbors': 12}\n",
            "  Precisión Promedio: 0.8732\n",
            "\n",
            "Decision Tree:\n",
            "  Mejor Modelo: Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('classifier', DecisionTreeClassifier(max_depth=6))])\n",
            "  Mejores Hiperparámetros: {'classifier__max_depth': 6}\n",
            "  Precisión Promedio: 0.8934\n",
            "\n",
            "Evaluando el modelo final para K-Nearest Neighbors...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.95      0.88      0.91        90\n",
            "         2.0       0.62      0.61      0.62        90\n",
            "         3.0       1.00      0.87      0.93        90\n",
            "         4.0       0.98      0.93      0.95        90\n",
            "         5.0       0.91      0.91      0.91        90\n",
            "         6.0       0.61      0.78      0.69        90\n",
            "         7.0       0.98      0.99      0.98        89\n",
            "\n",
            "    accuracy                           0.85       629\n",
            "   macro avg       0.87      0.85      0.86       629\n",
            "weighted avg       0.87      0.85      0.86       629\n",
            "\n",
            "\n",
            "Evaluando el modelo final para Decision Tree...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.98      0.99        90\n",
            "         2.0       1.00      1.00      1.00        90\n",
            "         3.0       1.00      0.98      0.99        90\n",
            "         4.0       0.98      1.00      0.99        90\n",
            "         5.0       1.00      1.00      1.00        90\n",
            "         6.0       1.00      0.99      0.99        90\n",
            "         7.0       0.97      1.00      0.98        89\n",
            "\n",
            "    accuracy                           0.99       629\n",
            "   macro avg       0.99      0.99      0.99       629\n",
            "weighted avg       0.99      0.99      0.99       629\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepara tus modelos para producción haciendo lo siguiente:\n",
        "\n",
        "A)Opten los hiperparámetros óptimos utilizando todo el conjunto de datos con validación cruzada.\n",
        "\n",
        "B)Con los hiperparámetros óptimos, ajusta el modelo con todos los datos."
      ],
      "metadata": {
        "id": "1UQdcNdEH5rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Configuración para GridSearchCV\n",
        "param_grid_knn = {\n",
        "    'classifier__n_neighbors': np.arange(1, 21)  # Probar valores de k entre 1 y 20\n",
        "}\n",
        "\n",
        "param_grid_tree = {\n",
        "    'classifier__max_depth': np.arange(1, 21)  # Probar valores de max_depth entre 1 y 20\n",
        "}\n",
        "\n",
        "# Modelos a evaluar con GridSearchCV\n",
        "modelos = {\n",
        "    'K-Nearest Neighbors': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'param_grid': param_grid_knn\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'param_grid': param_grid_tree\n",
        "    }\n",
        "}\n",
        "\n",
        "# Buscar los mejores hiperparámetros utilizando todo el conjunto de datos\n",
        "resultados = {}\n",
        "for nombre, info in modelos.items():\n",
        "    print(f\"Optimizando {nombre}...\")\n",
        "\n",
        "    # Crear un pipeline que escale las variables y aplique el modelo\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', info['model'])\n",
        "    ])\n",
        "\n",
        "    # Configurar GridSearchCV para búsqueda de hiperparámetros\n",
        "    grid_search = GridSearchCV(pipeline, info['param_grid'], cv=5, scoring='accuracy')\n",
        "\n",
        "    # Ajustar GridSearchCV con todo el conjunto de datos\n",
        "    grid_search.fit(variables, clases)\n",
        "\n",
        "    # Guardar los resultados\n",
        "    resultados[nombre] = {\n",
        "        'mejor_modelo': grid_search.best_estimator_,\n",
        "        'mejores_parametros': grid_search.best_params_\n",
        "    }\n",
        "\n",
        "# Imprimir los resultados\n",
        "for nombre, info in resultados.items():\n",
        "    print(f\"\\n{nombre}:\")\n",
        "    print(f\"  Mejor Modelo: {info['mejor_modelo']}\")\n",
        "    print(f\"  Mejores Hiperparámetros: {info['mejores_parametros']}\")\n",
        "\n",
        "# Ajustar el modelo final con todos los datos\n",
        "for nombre, info in resultados.items():\n",
        "    print(f\"\\nAjustando el modelo final para {nombre}...\")\n",
        "    final_model = info['mejor_modelo']\n",
        "    final_model.fit(variables, clases)\n",
        "    print(f\"{nombre} ajustado con todos los datos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIuB-2mSH3MI",
        "outputId": "54f7b7c6-73f6-4052-e9af-fec651d0e1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizando K-Nearest Neighbors...\n",
            "Optimizando Decision Tree...\n",
            "\n",
            "K-Nearest Neighbors:\n",
            "  Mejor Modelo: Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('classifier', KNeighborsClassifier(n_neighbors=6))])\n",
            "  Mejores Hiperparámetros: {'classifier__n_neighbors': 6}\n",
            "\n",
            "Decision Tree:\n",
            "  Mejor Modelo: Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('classifier', DecisionTreeClassifier(max_depth=13))])\n",
            "  Mejores Hiperparámetros: {'classifier__max_depth': 13}\n",
            "\n",
            "Ajustando el modelo final para K-Nearest Neighbors...\n",
            "K-Nearest Neighbors ajustado con todos los datos.\n",
            "\n",
            "Ajustando el modelo final para Decision Tree...\n",
            "Decision Tree ajustado con todos los datos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Observas un problema en cuanto al balanceo de las clases? ¿Por qué?**\n",
        "\n",
        "Cuando los datos no son balanceados los modelos pueden estar sesgados hacia la clase mayoritaria.\n",
        "\n",
        "**¿Qué modelo o modelos fueron efectivos para clasificar tus datos? ¿Observas algo especial sobre los modelos? Argumenta tu respuesta.**\n",
        "\n",
        "K-Nearest Neighbors parece ser efectivo si las características están bien distribuidas y los datos tienen una estructura clara.\n",
        "\n",
        "Decision Tree tambien parece ser efectivo con este set de datos, en el caso de los datos ya balanceados el modelo Gaussian Naive Bayes parece ser muy efectivo.\n",
        "\n",
        "**¿Observas alguna mejora importante al optimizar hiperparámetros? ¿Es el resultado que esperabas? Argumenta tu respuesta.**\n",
        "\n",
        "Al optimizar hiperparámetros, podemos mejorar la precisión del modelo al ajustar parámetros clave. Esto lo logramos haciendo que el modelo se adapte mejor a nuestros datos.\n",
        "\n",
        "**¿Qué inconvenientes hay al encontrar hiperparámetros? ¿Por qué?**\n",
        "\n",
        " La búsqueda exhaustiva de hiperparámetros puede ser muy costosa en términos de tiempo y recursos computacionales"
      ],
      "metadata": {
        "id": "Ne5h-LYyJG9h"
      }
    }
  ]
}